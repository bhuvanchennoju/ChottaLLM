{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens in train: 0.1M\n",
      "number of tokens in valid: 0.0251049M\n",
      "number of tokens in test: 0.0287645M\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data(npysplit):\n",
    "    data = np.load(npysplit)\n",
    "    return data\n",
    "\n",
    "data_dir = \"/n/projects/kc2819/projects/ChotaLLM/data/wikitext2\"\n",
    "trn_path, val_path, tst_path = data_dir + \"/wikitext-2-raw-v1_train_000000.npy\", data_dir + \"/wikitext-2-raw-v1_validation_000000.npy\", data_dir + \"/wikitext-2-raw-v1_test_000000.npy\"\n",
    "train_data = load_data(trn_path)\n",
    "valid_data = load_data(val_path)\n",
    "test_data = load_data(tst_path)\n",
    "\n",
    "\n",
    "print(f'number of tokens in train: {len(train_data)/10e6}M')\n",
    "print(f'number of tokens in valid: {len(valid_data)/10e6}M')\n",
    "print(f'number of tokens in test: {len(test_data)/10e6}M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([50256, 50256,   796,   569, 18354,  7496, 17740,  6711,   796,\n",
       "          220,   198, 50256, 50256,  2311,    73, 13090,   645,   569,\n",
       "        18354,  7496,   513,  1058,   791, 47398, 17740,   357,  4960,\n",
       "         1058, 10545,   230,    99,   161,   254,   112,  5641, 44444,\n",
       "         9202, 25084, 24440, 12675, 11839,    18,   837,  6578,   764,\n",
       "          569, 18354,  7496,   286,   262, 30193,   513,  1267,   837,\n",
       "         8811,  6412,   284,   355,   569, 18354,  7496, 17740,  6711,\n",
       "         2354,  2869,   837,   318,   257, 16106,  2597,  2488,    12,\n",
       "           31,  2712,  2008,   983,  4166,   416, 29490,   290,  6343,\n",
       "           13, 44206,   329,   262, 14047, 44685,   764, 28728,   287,\n",
       "         3269,  2813,   287,  2869,   837,   340,   318,   262,  2368,\n",
       "          983], dtype=uint16),\n",
       " array([50256, 50256,   796,  5199,   347,  2852,   353,   796,   220,\n",
       "          198, 50256, 50256,  5199,   347,  2852,   353,   318,   281,\n",
       "         3594,  2646,   837,  5581,   290, 21421,  8674,   764,   679,\n",
       "          550,   257,  8319,  2488,    12,    31, 20495,  2597,   319,\n",
       "          262,  5581,  2168,   383,  3941,   287,  4751,   764,   770,\n",
       "          373,  3940,   416,   257, 20495,  2597,   287,   262,   711,\n",
       "         2332,   684,  3194,   416, 11288, 37072,   837,   543,   373,\n",
       "         6157,   287,  5878,   379,   262,  8111,  3078, 15752,   764,\n",
       "          679,   550,   257,  8319,  2597,   287,   262,  5581,  2168,\n",
       "         8974,  1757,  1024,   276,   287,  6244,   764,   554,  5472,\n",
       "          347,  2852,   353, 11406,   257,  2597,   355,   366, 13854,\n",
       "          366], dtype=uint16),\n",
       " array([50256, 50256,   796,  8074, 20272,  9106,  3876,   385,   796,\n",
       "          220,   198, 50256, 50256,  8074, 20272,  9106,  3876,   385,\n",
       "          837,  1900,   355,   262,  3427, 43657,   393,  2219, 43657,\n",
       "          837,   318,   257,  4693,   286, 26573,   276, 43657,   422,\n",
       "          262, 10183, 10596, 10692,   837, 19517,  6896,   290,  3354,\n",
       "          286,   262,  2619,  6896,   764,   632,   318,  7173,  3519,\n",
       "          284,   262,  1605, 43657,   837,   367,    13, 45630, 41141,\n",
       "          764,   632,   743,  1663,   284,   257,  4129,   286,  3126,\n",
       "        12067,   357,  1987,   287,  1267,   290,   257,  2347,   286,\n",
       "          718, 37075,   357,  1511, 18360,  1267,   837,   290, 13062,\n",
       "          257, 39089,  5166,   286, 28421,   764,   554,  1204,   837,\n",
       "          262], dtype=uint16))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:100], test_data[:100], valid_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"/n/projects/kc2819/projects/ChotaLLM\")\n",
    "\n",
    "from src.dataUtils import CustomDataset, CustomDataloader, CustomTokenizer\n",
    "\n",
    "batch_size = 5\n",
    "block_size = 32\n",
    "embedding_size = 12\n",
    "\n",
    "tokenizer = CustomTokenizer()\n",
    "\n",
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|endoftext|> = Valkyria Chronicles III = \n",
      "<|endoftext|><|endoftext|> Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \n",
      "<|endoftext|> The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      "<|endoftext|> It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
      "<|endoftext|><|endoftext|> = = Gameplay = = \n",
      "<|endoftext|><|endoftext|> As with previous Valkyira Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main heroines , although they take a very minor role . \n",
      "<|endoftext|> The game 's battle system , the BliTZ system , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters ' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \n",
      "<|endoftext|> Troops are divided into five classes : Scouts , Shocktroopers , Engineers , Lancers and Armored Soldier . Troopers can switch classes by changing their assigned\n"
     ]
    }
   ],
   "source": [
    "seq = train_data[:1000]\n",
    "print(tokenizer.decode_np(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(trn_path, block_size= block_size)\n",
    "valid_dataset = CustomDataset(val_path, block_size= block_size)\n",
    "test_dataset = CustomDataset(tst_path, block_size= block_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31250 7845 8988\n",
      "train (tensor([50256, 50256,   796,   569, 18354,  7496, 17740,  6711,   796,   220,\n",
      "          198, 50256, 50256,  2311,    73, 13090,   645,   569, 18354,  7496,\n",
      "          513,  1058,   791, 47398, 17740,   357,  4960,  1058, 10545,   230,\n",
      "           99,   161]), tensor([50256,   796,   569, 18354,  7496, 17740,  6711,   796,   220,   198,\n",
      "        50256, 50256,  2311,    73, 13090,   645,   569, 18354,  7496,   513,\n",
      "         1058,   791, 47398, 17740,   357,  4960,  1058, 10545,   230,    99,\n",
      "          161,   254])) \n",
      " valid (tensor([50256, 50256,   796,  8074, 20272,  9106,  3876,   385,   796,   220,\n",
      "          198, 50256, 50256,  8074, 20272,  9106,  3876,   385,   837,  1900,\n",
      "          355,   262,  3427, 43657,   393,  2219, 43657,   837,   318,   257,\n",
      "         4693,   286]), tensor([50256,   796,  8074, 20272,  9106,  3876,   385,   796,   220,   198,\n",
      "        50256, 50256,  8074, 20272,  9106,  3876,   385,   837,  1900,   355,\n",
      "          262,  3427, 43657,   393,  2219, 43657,   837,   318,   257,  4693,\n",
      "          286, 26573])) \n",
      " test (tensor([50256, 50256,   796,  5199,   347,  2852,   353,   796,   220,   198,\n",
      "        50256, 50256,  5199,   347,  2852,   353,   318,   281,  3594,  2646,\n",
      "          837,  5581,   290, 21421,  8674,   764,   679,   550,   257,  8319,\n",
      "         2488,    12]), tensor([50256,   796,  5199,   347,  2852,   353,   796,   220,   198, 50256,\n",
      "        50256,  5199,   347,  2852,   353,   318,   281,  3594,  2646,   837,\n",
      "         5581,   290, 21421,  8674,   764,   679,   550,   257,  8319,  2488,\n",
      "           12,    31]))\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(valid_dataset), len(test_dataset))\n",
    "print(f'train', train_dataset[0],'\\n', f'valid', valid_dataset[0],'\\n', f'test', test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets test the dataloaders\n",
    "train_loader = CustomDataloader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = CustomDataloader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = CustomDataloader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 2162, 19627, 22543,   837,  7927,  2488,    12,    31,  8900,   837,\n",
       "             290,  3362,  1482,    74,  2815,   837,   423,  2846,  2491,   832,\n",
       "           13130,   764,   220,   198, 50256,  3899,   509,    13, 43766,   837,\n",
       "             257,  9755],\n",
       "          [  618,  3688,   284,   262, 13580,   286,   632,    89,   321,   509,\n",
       "             705,   272,  7900,    74,  2873,   780,  9398,   705,   509,   705,\n",
       "             259,  1395,   566, 28415,  1178, 28814,   837,   290,   339,   750,\n",
       "             407, 19594],\n",
       "          [ 9337,   290,   373,   523,  3772,   284,   423,  1392,  1978,   351,\n",
       "             683,   532,   475,   783,   339,   705,    82, 34781,   340,   764,\n",
       "             366,  3700,   635,  6848,   673,   373,   491,  2967,   284,  2193,\n",
       "           25176,   561],\n",
       "          [  815,   764,   843,   749,   286,   262,  1692,  2489,  5745,   837,\n",
       "            4928,  5745,   423,  3888,   287,   326,  4571,   764,   383,  1917,\n",
       "             318,   262,  3061,   764,   764,   764,   383,  1743, 33741,  3356,\n",
       "             837,   484],\n",
       "          [16937,   257,  7696,  2256,   379,  2986, 38083,   764,   220,   198,\n",
       "           50256, 50256,   796,   796,   796,  2986, 38083,   796,   796,   796,\n",
       "             220,   198, 50256, 50256,   383,  5398,  1368,   319,  2986, 38083,\n",
       "             416,   262]]),\n",
       "  tensor([[19627, 22543,   837,  7927,  2488,    12,    31,  8900,   837,   290,\n",
       "            3362,  1482,    74,  2815,   837,   423,  2846,  2491,   832, 13130,\n",
       "             764,   220,   198, 50256,  3899,   509,    13, 43766,   837,   257,\n",
       "            9755,   837],\n",
       "          [ 3688,   284,   262, 13580,   286,   632,    89,   321,   509,   705,\n",
       "             272,  7900,    74,  2873,   780,  9398,   705,   509,   705,   259,\n",
       "            1395,   566, 28415,  1178, 28814,   837,   290,   339,   750,   407,\n",
       "           19594,   465],\n",
       "          [  290,   373,   523,  3772,   284,   423,  1392,  1978,   351,   683,\n",
       "             532,   475,   783,   339,   705,    82, 34781,   340,   764,   366,\n",
       "            3700,   635,  6848,   673,   373,   491,  2967,   284,  2193, 25176,\n",
       "             561,  1210],\n",
       "          [  764,   843,   749,   286,   262,  1692,  2489,  5745,   837,  4928,\n",
       "            5745,   423,  3888,   287,   326,  4571,   764,   383,  1917,   318,\n",
       "             262,  3061,   764,   764,   764,   383,  1743, 33741,  3356,   837,\n",
       "             484,  1624],\n",
       "          [  257,  7696,  2256,   379,  2986, 38083,   764,   220,   198, 50256,\n",
       "           50256,   796,   796,   796,  2986, 38083,   796,   796,   796,   220,\n",
       "             198, 50256, 50256,   383,  5398,  1368,   319,  2986, 38083,   416,\n",
       "             262, 49967]])),\n",
       " (tensor([[ 8564, 13871,   286,   262,  2141,   381,  1754,  6482,   286, 35949,\n",
       "           33576,   843,   398,   276,  3609,   705,    82, 10958,   764,   383,\n",
       "            5440,   705,    82,  6224,   373,  3414,   287,  3269,  8309,   837,\n",
       "            1978,   351],\n",
       "          [24933,   326,   925,   510,   262,  6638,  3265,   379,   262,   640,\n",
       "             764,  9676,   837,   416,   262,   886,   286,   262,  1175,  2048,\n",
       "            1160,  4064,   286,   883,   508,  4983,   287,   262,  6638,  3386,\n",
       "             550,   587],\n",
       "          [   11,    31, 12877,  3625,   357, 44300,   285,  1267,   764,  1318,\n",
       "             547,   645,  2252,   569,  2304,   608,  2686, 30371,   287, 25656,\n",
       "             544,   764,   220,   198, 50256,   554,   262,  7024,  2714,   262,\n",
       "            1708,   614],\n",
       "          [ 1024, 46525,  1486,   689, 12382,   355,   262,  2607,   366,  8258,\n",
       "            3516,   366,   618,   339, 10069,   326,   339, 10732,  1438, 15940,\n",
       "            1088,   284,  3368,  7445,   588,   262,   530,  1024, 46525,   290,\n",
       "            3899,   547],\n",
       "          [ 5867,  2488,    12,    31, 14896,  2042,   582,   366,  2427,   837,\n",
       "           24433,   284,  5806,   257,  3735,  6050,   588,   883,   973,   287,\n",
       "             262,  8235, 19478, 14424,  2646,   383, 11959,   774,  8129,  2162,\n",
       "             339,   373]]),\n",
       "  tensor([[13871,   286,   262,  2141,   381,  1754,  6482,   286, 35949, 33576,\n",
       "             843,   398,   276,  3609,   705,    82, 10958,   764,   383,  5440,\n",
       "             705,    82,  6224,   373,  3414,   287,  3269,  8309,   837,  1978,\n",
       "             351,  5996],\n",
       "          [  326,   925,   510,   262,  6638,  3265,   379,   262,   640,   764,\n",
       "            9676,   837,   416,   262,   886,   286,   262,  1175,  2048,  1160,\n",
       "            4064,   286,   883,   508,  4983,   287,   262,  6638,  3386,   550,\n",
       "             587,  4642],\n",
       "          [   31, 12877,  3625,   357, 44300,   285,  1267,   764,  1318,   547,\n",
       "             645,  2252,   569,  2304,   608,  2686, 30371,   287, 25656,   544,\n",
       "             764,   220,   198, 50256,   554,   262,  7024,  2714,   262,  1708,\n",
       "             614,   739],\n",
       "          [46525,  1486,   689, 12382,   355,   262,  2607,   366,  8258,  3516,\n",
       "             366,   618,   339, 10069,   326,   339, 10732,  1438, 15940,  1088,\n",
       "             284,  3368,  7445,   588,   262,   530,  1024, 46525,   290,  3899,\n",
       "             547,   287],\n",
       "          [ 2488,    12,    31, 14896,  2042,   582,   366,  2427,   837, 24433,\n",
       "             284,  5806,   257,  3735,  6050,   588,   883,   973,   287,   262,\n",
       "            8235, 19478, 14424,  2646,   383, 11959,   774,  8129,  2162,   339,\n",
       "             373,  4191]])),\n",
       " (tensor([[  286,   262,  6846,  2063,   286,   262,   678,   400,  2488,    12,\n",
       "              31,  4289,   543,  2950,  6953,   565,  5643,  7685,  2950, 17091,\n",
       "            4028,   393, 21022,  1022,  1218,  2488,    12,    31,  2494, 19014,\n",
       "            5635,   764],\n",
       "          [ 2488,    12,    31,   969,  2488,    12,    31,  1001,   500,   764,\n",
       "             220,   198, 50256, 50256,   796,   796,  7343,   286,  5994,   471,\n",
       "              33,   314, 34031,   796,   796,   220,   198, 50256, 50256,  1160,\n",
       "            5994,   471],\n",
       "          [  284,  1592,   262,  5764,   837,   262,   717,  1201, 43052,  1173,\n",
       "             402,  4660,  2634,   287,   262,  5816,  1622,   764,   220,   198,\n",
       "           50256, 50256,   796,   796,   796,   796,  2321,  1622,  1058,  5934,\n",
       "            6960, 17490],\n",
       "          [ 2488,    12,    31,   352,  1267,   290,  7431,   261,  2944,    82,\n",
       "             592,   323, 23889,   357,   371,  2488,    12,    31,   718,  1267,\n",
       "             422,  8909,  8742,   837,   832,  4670, 26361,  2254,   837,   510,\n",
       "             284, 10844],\n",
       "          [50256, 50256,  8114, 20019,   318,  1900,   329,   465, 35444,  3073,\n",
       "             837,  1690,   852,  3417,   355,   366,  5156,  2488,    12,    31,\n",
       "            7452,   366,   764,  1881, 28823, 24998,   837,   366, 20019,  3073,\n",
       "             588,   339]]),\n",
       "  tensor([[  262,  6846,  2063,   286,   262,   678,   400,  2488,    12,    31,\n",
       "            4289,   543,  2950,  6953,   565,  5643,  7685,  2950, 17091,  4028,\n",
       "             393, 21022,  1022,  1218,  2488,    12,    31,  2494, 19014,  5635,\n",
       "             764,   887],\n",
       "          [   12,    31,   969,  2488,    12,    31,  1001,   500,   764,   220,\n",
       "             198, 50256, 50256,   796,   796,  7343,   286,  5994,   471,    33,\n",
       "             314, 34031,   796,   796,   220,   198, 50256, 50256,  1160,  5994,\n",
       "             471,    33],\n",
       "          [ 1592,   262,  5764,   837,   262,   717,  1201, 43052,  1173,   402,\n",
       "            4660,  2634,   287,   262,  5816,  1622,   764,   220,   198, 50256,\n",
       "           50256,   796,   796,   796,   796,  2321,  1622,  1058,  5934,  6960,\n",
       "           17490,  2488],\n",
       "          [   12,    31,   352,  1267,   290,  7431,   261,  2944,    82,   592,\n",
       "             323, 23889,   357,   371,  2488,    12,    31,   718,  1267,   422,\n",
       "            8909,  8742,   837,   832,  4670, 26361,  2254,   837,   510,   284,\n",
       "           10844, 16617],\n",
       "          [50256,  8114, 20019,   318,  1900,   329,   465, 35444,  3073,   837,\n",
       "            1690,   852,  3417,   355,   366,  5156,  2488,    12,    31,  7452,\n",
       "             366,   764,  1881, 28823, 24998,   837,   366, 20019,  3073,   588,\n",
       "             339,  8794]])))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader)), next(iter(valid_loader)), next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 32]) torch.Size([5, 32])\n",
      "torch.Size([5, 32]) torch.Size([5, 32])\n",
      "torch.Size([5, 32]) torch.Size([5, 32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trn_batch = next(iter(train_loader))\n",
    "print(trn_batch[0].shape, trn_batch[1].shape) # batch_size, block_size\n",
    "\n",
    "tst_batch = next(iter(test_loader))\n",
    "print(tst_batch[0].shape, tst_batch[1].shape)\n",
    "\n",
    "val_batch = next(iter(valid_loader))\n",
    "print(val_batch[0].shape, val_batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic datasets and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import tensor, long\n",
    "\n",
    "\n",
    "def load_tokens(filename):\n",
    "    npt = np.load(filename)\n",
    "    npt = npt.astype(np.int32) \n",
    "    ptt = tensor(npt, dtype=long)\n",
    "    return ptt\n",
    "\n",
    "\n",
    "class DataLoaderLite:\n",
    "\n",
    "    def __init__(self,B,T,process_rank,num_processes,split, master_process = True):\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        self.process_rank = process_rank\n",
    "        self.num_processes = num_processes\n",
    "        assert split in ['train','valid','test'], \"split should be either train, valid or test\"\n",
    "         \n",
    "        data_root = '/n/projects/kc2819/projects/ChotaLLM/data/wikitext2'\n",
    "        shards = os.listdir(data_root)\n",
    "\n",
    "        shards = [ shard for shard in shards if shard.endswith('.npy')]\n",
    "\n",
    "        shards = [s for s in shards if split in s]\n",
    "        shards = sorted(shards)\n",
    "        shards = [os.path.join(data_root,s) for s in shards]\n",
    "        self.shards = shards\n",
    "\n",
    "        assert len(self.shards) > 0, \"No shards found in the data directory\"\n",
    "\n",
    "        if master_process:\n",
    "            print(f\"Found {len(self.shards)} shards for {split} split\")\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    # what happens when we reset the dataloader\n",
    "    # when we reset the dataloader, we reset the current shard to 0, that means we start from the first shard in the list and tokens are loaded from the first shard in the list\n",
    "    # the current position is set to B * T * process_rank, that means we start from the beginning of the shard and the tokens are loaded from the beginning of the shard\n",
    "        \n",
    "    # if the process rank is 0, then the current position is 0, if the process rank is 1, then the current position is B * T, if the process rank is 2, then the current position is 2 * B * T and so on\n",
    "    # this is done to ensure that the data is loaded in a distributed manner, that is each process loads a different part of the data\n",
    "    # the tokens are loaded from the current position to the current position + B * T + 1, that is we load B * T tokens for the inputs and B * T tokens for the targets\n",
    "        \n",
    "    # this is okay if the tokens are in one big array, but if the tokens are in multiple shards, then we need to load the tokens from the current shard\n",
    "    # if the current position + B * T * num_processes + 1 is greater than the length of the tokens, then we move to the next shard\n",
    "    # we set the current shard to the next shard, and load the tokens from the next shard\n",
    "        \n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self.current_shard = 0\n",
    "        self.tokens = load_tokens(self.shards[self.current_shard])\n",
    "        print(len(self.tokens))\n",
    "        self.current_position = self.B * self.T * self.process_rank\n",
    "\n",
    "    def next_batch(self):\n",
    "        B,T = self.B, self.T\n",
    "        buf = self.tokens[self.current_position:self.current_position + B*T + 1]\n",
    "        print(len(buf), len(self.tokens), len(self.tokens) - self.current_position, len(self.tokens) - len(buf))\n",
    "        x = (buf[:-1]).view(B, T) # inputs\n",
    "        y = (buf[1:]).view(B, T) # targets\n",
    "\n",
    "        self.current_position += B * T * self.num_processes\n",
    "        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):\n",
    "            self.current_shard = (self.current_shard + 1) % len(self.shards)\n",
    "            self.tokens = load_tokens(self.shards[self.current_shard])\n",
    "            self.current_position = B * T * self.process_rank\n",
    "        return x, y # B x T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 shards for train split\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "block_size = 450\n",
    "dataloder = DataLoaderLite(B=batch_size, T=block_size, process_rank=2, num_processes=2, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45001 1000000 910000 954999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180000, 0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataloder.next_batch()\n",
    "dataloder.current_position, dataloder.current_shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 450]), torch.Size([100, 450]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import tensor, stack, long\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "\n",
    "class ShardDataset(Dataset):\n",
    "    def __init__(self, data_dir, block_size=128, file_extension='.npy', split='train', process_rank=0, num_processes=1):\n",
    "        self.data_dir = data_dir\n",
    "        self.block_size = block_size\n",
    "        self.file_extension = file_extension\n",
    "        self.split = split\n",
    "        self.process_rank = process_rank\n",
    "        self.num_processes = num_processes\n",
    "        self.shards = self._load_shards()\n",
    "        self.current_shard_idx = process_rank\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_shards(self):\n",
    "        shards = [os.path.join(self.data_dir, f) for f in os.listdir(self.data_dir) if f.endswith(self.file_extension) and self.split in f]\n",
    "        shards.sort()\n",
    "        assert len(shards) > 0, f\"No shards found in directory {self.data_dir} for split {self.split}.\"\n",
    "        return shards\n",
    "\n",
    "    def _load_data(self):\n",
    "        data = np.load(self.shards[self.current_shard_idx])\n",
    "        if data.dtype == np.int16:\n",
    "            data = data.astype(np.int32)\n",
    "        data = tensor(data, dtype=long)\n",
    "        return data\n",
    "\n",
    "    def _next_shard(self):\n",
    "        self.current_shard_idx = (self.current_shard_idx + self.num_processes) % len(self.shards)\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(np.load(shard)) for shard in self.shards) // (self.block_size * self.num_processes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        local_idx = idx % (len(self.data) // self.block_size)\n",
    "        start_idx = local_idx * self.block_size\n",
    "        end_idx = start_idx + self.block_size if start_idx + self.block_size < len(self.data) else len(self.data)\n",
    "        inputs_ids = self.data[start_idx:end_idx]\n",
    "        labels = self.data[start_idx + 1:end_idx + 1]\n",
    "\n",
    "        if len(labels) < self.block_size:\n",
    "            labels = torch.cat((labels, self.data[:self.block_size - len(labels)]))\n",
    "\n",
    "        if local_idx == (len(self.data) // self.block_size) - 1:\n",
    "            self._next_shard()\n",
    "\n",
    "        return inputs_ids, labels\n",
    "\n",
    "\n",
    "class ShardDataloader:\n",
    "    def __init__(self, dataset: ShardDataset, batch_size=64, shuffle=True, pad=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.pad = pad\n",
    "        self.idxis = np.arange(len(self.dataset))\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.idxis)\n",
    "        self.str_idx = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.str_idx = 0\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.idxis)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.str_idx >= len(self.idxis):\n",
    "            raise StopIteration\n",
    "\n",
    "        end_idx = min(self.str_idx + self.batch_size, len(self.idxis))\n",
    "        batch_idxis = self.idxis[self.str_idx:end_idx]\n",
    "        self.str_idx = end_idx\n",
    "\n",
    "        batch = [self.dataset[i] for i in batch_idxis]\n",
    "        inputs, labels = zip(*batch)\n",
    "        inputs = stack(inputs)\n",
    "        labels = stack(labels)\n",
    "\n",
    "        if self.pad:\n",
    "            inputs = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "            labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 6324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    process_rank = 2\n",
    "    num_processes = 3\n",
    "\n",
    "    dataset = ShardDataset(\n",
    "        data_dir= \"/n/projects/kc2819/projects/ChotaLLM/data/wikitext2\",\n",
    "        block_size=128,\n",
    "        split='train',\n",
    "        process_rank=process_rank,\n",
    "        num_processes=num_processes\n",
    "    )\n",
    "\n",
    "    print(f\"Dataset length: {len(dataset)}\")\n",
    "\n",
    "    sampler = DistributedSampler(dataset, num_replicas=num_processes, rank=process_rank, shuffle=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, sampler=sampler, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "    # for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "    #     print(f\"Process {process_rank} - Batch {batch_idx}: {inputs[0].shape}, {labels[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.num_replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor, long, cat\n",
    "import os\n",
    "\n",
    "class ShardDatasets:\n",
    "\n",
    "    def __init__(self,dataset_dir, block_size = 128, file_extension = '.npy', split = 'train'):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.block_size = block_size\n",
    "        self.file_extension = file_extension\n",
    "        self.split = split\n",
    "\n",
    "        self.shards = self._load_shards()\n",
    "        self.current_shard_idx = 0\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_shards(self):\n",
    "        shards = [os.path.join(self.dataset_dir, f) for f in os.listdir(self.dataset_dir) if f.endswith(self.file_extension) and self.split in f]\n",
    "        shards.sort()\n",
    "        assert len(shards) > 0, f\"No shards found in directory {self.dataset_dir} for split {self.split}.\"\n",
    "        return shards\n",
    "\n",
    "    def _load_data(self):\n",
    "        if self.file_extension == '.npy':\n",
    "            data = np.load(self.shards[self.current_shard_idx])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if data.dtype == np.int16:\n",
    "            data = data.astype(np.int32)\n",
    "        return  tensor(data, dtype=long)\n",
    "\n",
    "    def _next_shard(self):\n",
    "        self.current_shard_idx = (self.current_shard_idx + 1) % len(self.shards)\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(np.load(shard)) for shard in self.shards) // self.block_size # this is total number of blocks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        shard_size = len(self.data) // self.block_size\n",
    "        while idx >= shard_size:\n",
    "            idx -= shard_size\n",
    "            self._next_shard()\n",
    "            shard_size = len(self.data) // self.block_size\n",
    "\n",
    "        start_idx = idx * self.block_size\n",
    "        end_idx = start_idx + self.block_size if start_idx + self.block_size < len(self.data) else len(self.data)\n",
    "        inputs_ids = self.data[start_idx:end_idx]\n",
    "        labels = self.data[start_idx + 1:end_idx + 1]\n",
    "\n",
    "        if len(labels) < self.block_size:\n",
    "            labels = cat((labels, self.data[:self.block_size - len(labels)]))\n",
    "\n",
    "        return inputs_ids, labels\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/n/projects/kc2819/projects/ChotaLLM/data/wikitext2\"\n",
    "train_dataset = ShardDatasets(data_dir, block_size= block_size, split='train', file_extension='.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75893"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n",
      "Parameter containing:\n",
      "tensor([[ 1.1204, -0.1094, -1.1308],\n",
      "        [ 0.3742,  0.3927,  0.4792],\n",
      "        [-0.3982, -0.4998, -0.7896],\n",
      "        [-0.4837,  0.4450,  0.4109],\n",
      "        [-0.8308, -1.6025, -0.0689],\n",
      "        [ 0.8746, -0.6552,  0.5417],\n",
      "        [ 0.4448,  0.4127, -0.6123],\n",
      "        [ 0.1343, -0.5025, -0.8294],\n",
      "        [-1.9889, -0.1112,  0.2929],\n",
      "        [-0.2769, -0.4240, -0.1411]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# simple lookup table of index - num_embeddings with each index having embedding_dim vector representation\n",
    "emb_layer = nn.Embedding(num_embeddings = 10, embedding_dim = 3) # vocab_size, embedding_size\n",
    "\n",
    "print(emb_layer.weight.shape)\n",
    "\n",
    "print(emb_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3742,  0.3927,  0.4792],\n",
      "        [-0.3982, -0.4998, -0.7896],\n",
      "        [-0.4837,  0.4450,  0.4109]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "input_indicies = torch.tensor([1,2,3])\n",
    "map = emb_layer(input_indicies)\n",
    "print(map)\n",
    "print(map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor([[[ 0.3742,  0.3927,  0.4792],\n",
      "         [-0.3982, -0.4998, -0.7896],\n",
      "         [-0.4837,  0.4450,  0.4109]],\n",
      "\n",
      "        [[-0.8308, -1.6025, -0.0689],\n",
      "         [ 0.8746, -0.6552,  0.5417],\n",
      "         [ 0.4448,  0.4127, -0.6123]],\n",
      "\n",
      "        [[ 0.1343, -0.5025, -0.8294],\n",
      "         [-1.9889, -0.1112,  0.2929],\n",
      "         [-0.2769, -0.4240, -0.1411]]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "input_indicies = torch.tensor([[1,2,3],[4,5,6],[7,8,9]]) # batch of 3, with three tokens each\n",
    "print(input_indicies.shape)\n",
    "map = emb_layer(input_indicies)\n",
    "print(map)\n",
    "print(map.shape)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50256, 5303, 703, 389, 345, 1804], [50256, 72, 716, 1804, 922]]\n",
      "6\n",
      "[[50256, 5303, 703, 389, 345, 1804], [50256, 72, 716, 1804, 922, 0]]\n",
      "tensor([[50256,  5303,   703,   389,   345,  1804],\n",
      "        [50256,    72,   716,  1804,   922,     0]])\n"
     ]
    }
   ],
   "source": [
    "# lets create the sentence to embedding for the model\n",
    "\n",
    "sent_batch = [\n",
    "    'hi how are you doing',\n",
    "    'i am doing good',\n",
    "]\n",
    "\n",
    "tok_b = [tokenizer.encode(s) for s in sent_batch]\n",
    "print(tok_b)\n",
    "\n",
    "# lets pad the tokens\n",
    "max_len = max([len(t) for t in tok_b])\n",
    "print(max_len)\n",
    "\n",
    "padded = [t + [0]*(max_len - len(t)) for t in tok_b]\n",
    "\n",
    "print(padded)\n",
    "\n",
    "\n",
    "input_tensor = torch.tensor(padded)\n",
    "print(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inputblock(nn.Module): # inherit the base class\n",
    "\n",
    "    def __init__(self,vocab_size,block_size,embedding_size):\n",
    "        super(inputblock, self).__init__()   ## always need to call this super constructor to initialize the base class\n",
    "        self.tok_emb = nn.Embedding(vocab_size, embedding_size) # vocab_size * embedding_size look up table\n",
    "        # back in the day we used to add sin and cos positional encodings here, but now we just use embeddings for that\n",
    "        # this is because the model can learn the positional encodings as well\n",
    "        self.pos_emb = nn.Embedding(block_size, embedding_size) \n",
    "\n",
    "    def forward(self, batch):\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        sentence: 'hi how are you doing' ---> | gpt2 encoding | ---> 50256(eot),  5303,   703,   389,   345,  1804 --> this token vector (batch)\n",
    "\n",
    "        batch.shape = (B,T) ---> batch_size, block_size/context window\n",
    "\n",
    "                  | -> token embedding - (B,T,C) lookup table                         |\n",
    "        batch --> |                                                                   | -> pos + tok = (B,T,C) positional + token embeddings \n",
    "                  | -> positional embedding - (T,C) learnable positional embeddings   |                 positional embeddings casted to batch size\n",
    "                  \n",
    "        \n",
    "        \"\"\"\n",
    "        B,C = batch.shape\n",
    "        tok_emb = self.tok_emb(batch) # B,T,C\n",
    "        pos = torch.arange(C).expand(B,C).to(batch.device)\n",
    "        pos_emb = self.pos_emb(pos) # T,C\n",
    "        return tok_emb + pos_emb    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 6\n"
     ]
    }
   ],
   "source": [
    "B,T = input_tensor.shape\n",
    "print(B,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 12])\n"
     ]
    }
   ],
   "source": [
    "i2tr = inputblock(vocab_size = tokenizer.get_vocab_size(), block_size = T, embedding_size = embedding_size)\n",
    "\n",
    "out = i2tr(input_tensor)\n",
    "print(out.shape) # B,T,C = 2, 6, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attentionhead(nn.Module):\n",
    "\n",
    "    def __init__(self,emb_size,head_size):\n",
    "        super(attentionhead, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.head_size = head_size\n",
    "        assert emb_size % head_size == 0, 'embedding size must be divisible by head size'\n",
    "\n",
    "        # q,k,v embeddings \n",
    "        self.qkv = nn.Linear(emb_size, 3 * head_size,bias=False) # (B,T,hc) -> (B,T,hc) x 3              \n",
    "        self.register_buffer('tril', torch.tril(torch.ones(emb_size,emb_size))) # lower triangular matrix\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.size()\n",
    "        q,k,v = self.qkv(x).split(self.head_size, dim = 2) # I have to split this properly at head_size to unpack \n",
    "                                                           # (B,T,hc) -> (B,T,hc) x 3 -> (B,T,hc) x 3\n",
    "        \n",
    "        # w = softmax(qk^T/sqrt(d_k))v\n",
    "        w = q @ k.transpose(1,2) * (C ** -0.5) # (B,T,hc) x (B,hc,T) -> (B,T,T) \n",
    "        w = w.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # mask the upper triangular matrix\n",
    "        w = F.softmax(w,dim = 2) # (B,T,T)\n",
    "        return w @ v # (B,T,T) x (B,T,hc) -> (B,T,hc)\n",
    "    \n",
    "\n",
    "\n",
    "class attensionblock(nn.Module):\n",
    "\n",
    "    def __init__(self,emb_size,head_size):\n",
    "        super(attensionblock, self).__init__()\n",
    "        assert emb_size % head_size == 0, 'embedding size must be devisable by head size'\n",
    "        self.head_size = head_size\n",
    "        self.emb_size = emb_size\n",
    "        self.n_heads = self.emb_size // self.head_size\n",
    "\n",
    "        self.attention_heads = nn.ModuleList([attentionhead(emb_size,head_size) for _ in range(self.n_heads)])\n",
    "\n",
    "        self.fc = nn.Linear(emb_size,emb_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.size()\n",
    "        w = torch.cat([attn_head(x) for attn_head in self.attention_heads],dim = 2) # (B,T,hc) x n_heads -> (B,T,hc*n_heads)\n",
    "        return self.fc(w) # (B,T,hc*n_heads) -> (B,T,C)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 4])\n",
      "torch.Size([2, 6, 12])\n"
     ]
    }
   ],
   "source": [
    "attn = attentionhead(emb_size = embedding_size, head_size = 4)\n",
    "attn_out = attn(out)\n",
    "print(attn_out.shape) # B,T,C = 2, 6, 12\n",
    "\n",
    "attn_block = attensionblock(emb_size = embedding_size, head_size = 4)\n",
    "attn_block_out = attn_block(out)\n",
    "print(attn_block_out.shape) # B,T,C = 2, 6, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
